{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name of Members:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __APA, GIUSIPPI MARIA II DEL ROSARIO__\n",
    "- __OBEJERO, REY FERBS MAGALLON__\n",
    "- __RAMIREZ, BENMAR SIM GREFALDA__\n",
    "- __RAMOS, RONN PATRICK BICERA__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we chose for this machine project is the \"Sports\" dataset. \n",
    "\n",
    "Our project will have us go through the process of selecting a dataset, describing it, performing EDA, data preprocessing and cleaning, model training, HP tuning, model selection, and extracting insights from the data.\n",
    "\n",
    "We aim to leverage the data from the soccer matches to preduct the number of goals that will be scored during the remaining playtime. The target of this project is regression as we aim to predict a continous outcome, which is the **number of goals to be scored** during the remaining time.\n",
    "\n",
    "We will implement the use of machine learning and other techniques taught in class to build our predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is related to soccer matches and will be used to predict how many goals will be scored during the remaining match time. The dataset contains 10,000 such snapshots, each taken at a different, random point in time during a match. \n",
    "\n",
    "In the context of this dataset, a “snapshot” refers to a set of data points captured at a specific moment during a soccer match.\n",
    "\n",
    "As for the collection process, it can be inferred that the data might have been collected in real-time during this soccer match, capturing various events and statistics at different timestamps. This data would allow for more accurate predictions of future events based on the current state of the match, and whether it is best to bet on over or under a certain number of goals.\n",
    "\n",
    "There are only 7000 instances(rows) and 21 features(columns) in the dataset. Each of the features are statistics of both events for the home and away team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Variable Name** | **Description**|\n",
    "|--------------------------------------|----------------|\n",
    "|**uuid** | Snapshot’s unique ID|\n",
    "|**current_minute** | Match’s current minute, including 15 min half-time|\n",
    "|**home_score and away_score** | Home and away team’s goals.|\n",
    "|**home_yellow_cards and away_yellow_cards**| Home and away team’s yellow cards.|\n",
    "|**home_red_cards and away_red_cards**| Home and away team’s red cards.|\n",
    "|**home_attacks and away_attacks**| Home and away team’s attempted attacks.|\n",
    "|**home_dangerous_attacks and away_dangerous_attacks**| Home and away team’s dangerous attacks.|\n",
    "|**home_corners and away_corners**| Home and away team’s awarded corners.|\n",
    "|**home_off_target and away_off_target**| Home and away team’s off-target shots.|\n",
    "|**home_on_target and away_on_target**| Home and away team’s on-target shots.|\n",
    "|**home_possession and away_possession** |Home and away team’s ball possession %.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this machine project, we will utilize the following Python libraries:\n",
    "\n",
    "- `one`:\n",
    "- `two`:\n",
    "- `three`:\n",
    "- `four`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear_regression import compute_RMSE\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now be performing various methods of preprocessing and data cleaning to enhance the dataset's usability and suitability to our exploratory analysis and model training.\n",
    "\n",
    "This is also to ensure that the dataset will be ready for use, which means we will be checking for missing values, duplicates, outliers and other errors. Making it so that the data is in its correct representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and reading the Sports.csv\n",
    "sports = pd.read_csv(\"sports.csv\")\n",
    "sports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking for Missing Values**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code here indentifies and prints the columns in our sports Dataframe that contain missing values, first one counts the total number of missing values in each column, and if the count is greater than zero it shows us the list.\n",
    "\n",
    "This is an essential step, just so we can see if we have any columns that are missing data before we move on to other processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check each column for missing values\n",
    "missing_values = sports.isnull().sum()\n",
    "\n",
    "columns_with_missing_values = missing_values[missing_values > 0]\n",
    "print(columns_with_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking for Duplicates**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code identifies and removes duplicates rows in the sports DataFrame, it finds all the duplicate rows and seperates them and prints out the rows. Duplicates are removed from the original dataframe and will only keep the first occurence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the duplicates\n",
    "duplicate_uuids = sports.duplicated(keep=False)\n",
    "\n",
    "# Create a dataframe for duplicates\n",
    "duplicates = sports[duplicate_uuids]\n",
    "\n",
    "# Display the rows with duplicates\n",
    "print(\"Duplicate Entries:\\n\", duplicates)\n",
    "\n",
    "# Removing the duplicates if detected in dataframe\n",
    "if not duplicates.empty:\n",
    "    sports = sports.drop_duplicates(keep='first')\n",
    "    print(\"Duplicates removed. Dataset has {sports.shape[0]} rows.\")\n",
    "else:\n",
    "    print(\"No duplicates found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other Cleaning Processes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first process replaces infinite values with NaN, which is for undefined data. Drops any columns where there are more than 50% values are missing, while the last checks for inconsistencies in the possession data, wherein it looks for home_possession and way_possession variables that do not equate to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing any erroneous infinite values\n",
    "sports = sports.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Dropping columns with more than 50% missing values\n",
    "sports = sports.dropna(thresh=len(sports)*0.5, axis=1)\n",
    "\n",
    "# Check for incorrect possession percentages\n",
    "incorrect_possession_indices = sports[~(sports['home_possession'] + sports['away_possession'] == 100)].index\n",
    "\n",
    "if len(incorrect_possession_indices) > 0:\n",
    "    print(\"Found inconsistencies in possession data:\")\n",
    "    print(sports.loc[incorrect_possession_indices, ['home_possession', 'away_possession']])\n",
    "else:\n",
    "    print(\"Possession data is consistent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see there are percentages that don't equate to 100, but the difference is neglible because it is only from 99 to 100 which won't cause much noise in the analysis. It isn't exactly necessary to remove it at this point of the dataset but is also another consideration we took to prepare the if ever the dataset grew larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Type Checking**\n",
    "\n",
    "Having appropriate data types for the values in the dataset is crucial to data analysis and model training. Luckily for us, the dataset we currently have has the appropriate values as all of the variables and their values are appropriate to their data type.\n",
    "\n",
    "The importance of having correct data types is that we have the following:\n",
    "\n",
    "Data Integrity,\n",
    "Accuracy,\n",
    "Efficiency,\n",
    "Compatibility, \n",
    "and Reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing all of the present data types\n",
    "print(\"All data types present:\\n\", sports.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection and Treatment\n",
    "\n",
    "Outliers can significantly impact statistical measures and model performance. In the context of our dataset, outliers might represent unusual game conditions, errors in data collection, or truly exceptional events. \n",
    "\n",
    "Surprisingly enough, there are no major outliers in our dataset, because in the dataset, varying values like attacks, cards, and accuracy are all subject to the team's playstyle and ability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our Approach**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we performed winsorization on the dataset to make it robust against potential outliers in the future if ever there are any in the future, possibly when the dataset grows larger. By capping the data at specified percentiles we reduce the possible influed of these outliers. \n",
    "\n",
    "We also provided the before and after outlier treatment visualizations to identify the outliers (if there are any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to check for outliers\n",
    "outlier_columns = ['current_minute', 'home_yellow_cards', 'away_yellow_cards', 'home_on_target',\n",
    "                   'away_on_target', 'home_attacks', 'away_attacks', 'home_dangerous_attacks',\n",
    "                   'away_dangerous_attacks', 'home_corners', 'away_corners', 'home_off_target',\n",
    "                   'away_off_target', 'home_possession', 'away_possession']\n",
    "\n",
    "def winsorize(data, lower_percentile=5, upper_percentile=95):\n",
    "    # Winsorizes data by capping values at specified percentiles\n",
    "    lower_bound = np.percentile(data, lower_percentile)\n",
    "    upper_bound = np.percentile(data, upper_percentile)\n",
    "    return np.clip(data, lower_bound, upper_bound)\n",
    "\n",
    "def truncate(data, upper_bound):\n",
    "    # Truncates data by removing values exceeding the upper bound\n",
    "    return data[data <= upper_bound]\n",
    "\n",
    "def detect_possession_outliers(data, method='zscore', z_score_threshold=3, lower_bound=20, upper_bound=80):\n",
    "    home_possession = data['home_possession']\n",
    "    away_possession = data['away_possession']\n",
    "\n",
    "    if method == 'zscore':\n",
    "        # Z-score method (not used for normalization)\n",
    "        pass\n",
    "    elif method == 'percentile':\n",
    "        # Percentile-based method (not used for normalization)\n",
    "        pass\n",
    "    elif method == 'domain':\n",
    "        # Domain knowledge-based method\n",
    "        data['home_possession_outlier'] = np.where((home_possession < lower_bound) | (home_possession > upper_bound), True, False)\n",
    "        data['away_possession_outlier'] = np.where((away_possession < lower_bound) | (away_possession > upper_bound), True, False)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid outlier detection method. Choose 'zscore', 'percentile', or 'domain'.\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# Handle outliers for other columns\n",
    "for col in outlier_columns:\n",
    "    if col == 'current_minute':\n",
    "        sports[col] = truncate(sports[col], 105)\n",
    "    elif col.endswith('_cards'):\n",
    "        sports[col] = winsorize(sports[col], upper_percentile=80)\n",
    "    else:\n",
    "        sports[col] = winsorize(sports[col])\n",
    "\n",
    "# Choose a method for possession outliers and apply it\n",
    "sports = detect_possession_outliers(sports.copy(), method='domain', lower_bound=20, upper_bound=80)  # Example: using domain-based method\n",
    "\n",
    "# Calculate goals scored after current minute\n",
    "def calculate_remaining_goals(row):\n",
    "    total_goals = row['home_score'] + row['away_score']\n",
    "    goals_so_far = total_goals - row['home_score'] - row['away_score']\n",
    "    return total_goals - goals_so_far\n",
    "\n",
    "sports['goals_remaining'] = sports.apply(calculate_remaining_goals, axis=1)\n",
    "\n",
    "# Calculate additional features\n",
    "epsilon = 1e-10\n",
    "sports['home_attack_efficiency'] = sports['home_score'] / (sports['home_attacks'] + epsilon)\n",
    "sports['away_attack_efficiency'] = sports['away_score'] / (sports['away_attacks'] + epsilon)\n",
    "\n",
    "sports['home_shot_conversion_rate'] = sports['home_score'] / (sports['home_on_target'] + sports['home_off_target'] + epsilon)\n",
    "sports['away_shot_conversion_rate'] = sports['away_score'] / (sports['away_on_target'] + sports['away_off_target'] + epsilon)\n",
    "\n",
    "sports['possession_differential'] = sports['home_possession'] - sports['away_possession']\n",
    "\n",
    "# Select columns for normalization (excluding uuid)\n",
    "columns_to_normalize = [col for col in sports.columns if col != 'uuid']\n",
    "\n",
    "# Create a MinMaxScaler object (normalizes to 0 to 1 range)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Apply normalization to selected columns\n",
    "sports[columns_to_normalize] = scaler.fit_transform(sports[columns_to_normalize])\n",
    "\n",
    "# Visualize distributions after outlier treatment and normalization\n",
    "fig, axes = plt.subplots(nrows=len(outlier_columns) + 2, ncols=2, figsize=(15, 40))\n",
    "\n",
    "for i, col in enumerate(outlier_columns):\n",
    "    # Box plots\n",
    "    sns.boxplot(data=sports, x=col, ax=axes[i, 0])\n",
    "    axes[i, 0].set_title(f'{col} - Before Treatment')\n",
    "\n",
    "    sns.boxplot(data=sports, x=col, ax=axes[i, 1])\n",
    "    axes[i, 1].set_title(f'{col} - After Treatment')\n",
    "\n",
    "# Visualize possession data with outliers\n",
    "sns.boxplot(data=sports, x='home_possession', ax=axes[len(outlier_columns), 0], hue='home_possession_outlier')\n",
    "sns.boxplot(data=sports, x='away_possession', ax=axes[len(outlier_columns), 1], hue='away_possession_outlier')\n",
    "\n",
    "# Histograms for possession data with outliers\n",
    "sns.histplot(data=sports, x='home_possession', kde=True, ax=axes[len(outlier_columns) + 1, 0], hue='home_possession_outlier')\n",
    "sns.histplot(data=sports, x='away_possession', kde=True, ax=axes[len(outlier_columns) + 1, 1], hue='away_possession_outlier')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did boxplots and histograms for all relevant variables and utilized truncation and winsorization. \n",
    "\n",
    "In our current case, there are no obvious outliers, because the initial data might not have contained extreme values that would significantly impact the results. There is also the idea of playstyle variations where the teams at different current_minutes would have varying possessions, attacks, or accuracy.\n",
    "\n",
    "Despite this, still applying outlier detection methods still offers a safety net from future outliners. We also applied normalization to bring the features to a common scale between 0 and 1, this will help us ensure that there is feature scaling and improved algorithm performance from algorithms like such as neural networks and gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering**\n",
    "`goals_remaining`: This is our target variable, representing the number of goals scored in the remaining time of the match.\n",
    "\n",
    "Ratio of Attack to Goals\n",
    "\n",
    "`home_attack_efficiency`: Measures the efficiency of the home team in converting attacks into goals.\n",
    "`away_attack_efficiency`: Measures the efficiency of the away team in converting attacks into goals.\n",
    "\n",
    "Ratio of Shots to Goals\n",
    "\n",
    "`home_shot_conversion_rate`: Measures the efficiency of the home team in converting shots into goals.\n",
    "`away_shot_conversion_rate`: Measures the efficiency of the away team in converting shots into goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where current_minute is less than or equal to 0\n",
    "sports = sports[sports['current_minute'] > 0]\n",
    "\n",
    "# Calculate goals scored after current minute\n",
    "def calculate_potential_goals(row):\n",
    "    remaining_time = 105 - row['current_minute']\n",
    "    goals_so_far = row['home_score'] + row['away_score']\n",
    "    avg_goals_per_minute = goals_so_far / row['current_minute']\n",
    "    potential_goals = avg_goals_per_minute * remaining_time\n",
    "    return potential_goals\n",
    "\n",
    "sports['potential_goals'] = sports.apply(calculate_potential_goals, axis=1)\n",
    "\n",
    "# Filter out rows where the sum of home and away attacks and dangerous attacks is zero\n",
    "sports = sports[(sports['home_attacks'] + sports['home_dangerous_attacks'] > 0) & \n",
    "                (sports['away_attacks'] + sports['away_dangerous_attacks'] > 0)]\n",
    "\n",
    "# Filter out rows where the sum of home and away shots is zero\n",
    "sports = sports[(sports['home_on_target'] + sports['home_off_target'] > 0) & \n",
    "                (sports['away_on_target'] + sports['away_off_target'] > 0)]\n",
    "\n",
    "# Calculate additional features\n",
    "sports['home_attack_efficiency'] = sports['home_score'] / (sports['home_attacks'] + sports['home_dangerous_attacks'])\n",
    "sports['away_attack_efficiency'] = sports['away_score'] / (sports['away_attacks'] + sports['away_dangerous_attacks'])\n",
    "sports['home_shot_conversion_rate'] = sports['home_score'] / (sports['home_on_target'] + sports['home_off_target'])\n",
    "sports['away_shot_conversion_rate'] = sports['away_score'] / (sports['away_on_target'] + sports['away_off_target'])\n",
    "\n",
    "# Select new features for normalization\n",
    "new_features_to_normalize = ['potential_goals', 'home_attack_efficiency', 'away_attack_efficiency', \n",
    "                             'home_shot_conversion_rate', 'away_shot_conversion_rate']\n",
    "\n",
    "# Create a MinMaxScaler object (normalizes to 0-1 range)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply normalization to new features\n",
    "sports[new_features_to_normalize] = scaler.fit_transform(sports[new_features_to_normalize])\n",
    "\n",
    "print(sports['potential_goals'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping Features**\n",
    "\n",
    "Some data from the additional features were divided by zero therefore creating infinite values. The uuid column is a unique identifier that does not provide any predictive information, therefore it's correct to drop these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping irrelevant column\n",
    "sports = sports.drop('uuid', axis=1)\n",
    "\n",
    "# Replace infinite values with NaN\n",
    "sports.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "sports.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **correlation matrix** is a table showing the correlation coefficients between many variables. Each entry in the table shows the correlation between two variables. A correlation coefficient is a statistical measure that calculates the strength of the relationship between the relative movements of the two variables. The range of values for the correlation coefficient is -1.0 to 1.0. If a correlation is close to 1, it indicates a strong positive relationship between the variables. When that number is close to -1, the variables have a strong negative relationship.\n",
    "\n",
    "In the given heatmap:\n",
    "\n",
    "- Dark blue cells indicate a strong positive correlation, dark red cells indicate a strong negative correlation, and white cells indicate no correlation.\n",
    "\n",
    "- For example, 'home_score' and 'home_attack_efficiency' have a strong positive correlation. This suggests that as the home team's score increases, their attack efficiency also tends to increase.\n",
    "\n",
    "- Conversely, 'away_possession_outlier' and 'home_attack_efficiency' have a strong negative correlation, shown by a darker red shade and numerical value close to -1. This suggests that when the away team's possession is considered an outlier (either extremely high or low), the home team's attack efficiency tends to be lower.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = sports.corr()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title('Correlation Matrix of Sports DataFrame')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removal of Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to remove the card-related variables as they might not have a direct impact on specific metrics, and are focused on which specific players do get these cards, which is data not present. Attack efficiency and ratios of goals to shots has more of a direct influence to the number of goals.\n",
    "\n",
    "If the dataset did have the extra data for individual players, we believe that focusing more on the attack-related variables would give us a clearer answer as these unnecessary variables can add noise into our model and possibly lead to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['home_yellow_cards', 'away_yellow_cards', 'home_red_cards', 'away_red_cards']\n",
    "sports = sports.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA is a critical step in any data analysis or machine learning project. It allows us to understand the data’s characteristics, identify patterns and relationships, detect anomalies, inform feature engineering, and check assumptions. For instance, EDA on the ‘Sports’ dataset will provide insights into the factors influencing the number of goals scored during the remaining playtime. These insights will guide our choice of regression model and help us engineer features that improve our model’s predictive performance. \n",
    "\n",
    "We can try to look at the average goals remaining for all the games, to have a general idea of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_potential_goals = sports['potential_goals'].mean()\n",
    "\n",
    "print(f\"Average Potential Goals: {average_potential_goals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will generate a history plot of the goals_remaining variable to visualize its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.histplot(sports['potential_goals'], kde=True)\n",
    "plt.title('Distribution of Potential Goals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right-skewness for goals remaining indicates that while most matches have fewer goals remaining, there are some matches where a significantly higher number of goals are scored towards the end. This distribution suggests that matches can vary widely in the number of goals scored in the remaining time.\n",
    "\n",
    "Below we can first visualize the home attack efficiency and shot conversion rate, here in the Kernel Density Estimate (KDE), it's basically a smoothed out version of the histogram so we can better see the distribution and probability density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(sports['home_attack_efficiency'], kde=True)\n",
    "plt.title('Distribution of Home Attack Efficiency')\n",
    "plt.xlim(0, 1)  \n",
    "plt.show()\n",
    "\n",
    "sns.histplot(sports['home_shot_conversion_rate'], kde=True)\n",
    "plt.title('Distribution of Home Shot Conversion Rate')\n",
    "plt.xlim(0, 1) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can generate the away attack efficiency and away shot conversion rate. We see a significant difference in their KDE as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(sports['away_attack_efficiency'], kde=True)\n",
    "plt.title('Distribution of Away Attack Efficiency')\n",
    "plt.xlim(0, 1) \n",
    "plt.show()\n",
    "\n",
    "sns.histplot(sports['away_shot_conversion_rate'], kde=True)\n",
    "plt.title('Distribution of Away Shot Conversion Rate')\n",
    "plt.xlim(0, 1) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features attack_efficiency and shot_conversion_rate for both teams are right-skewed. This means that most teams have lower values for these features, indicating that they are generally less efficient in converting attacks into goals. However, there are a few teams with very high values, suggesting that only a small number of teams achieve high efficiency in these areas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='home_attack_efficiency', y='potential_goals', data=sports)\n",
    "plt.title('Home Attack Efficiency vs. Goals Remaining')\n",
    "plt.xlabel('Home Attack Efficiency')\n",
    "plt.ylabel('Potential Goals')\n",
    "plt.show()\n",
    "\n",
    "sns.scatterplot(x='home_shot_conversion_rate', y='potential_goals', data=sports)\n",
    "plt.title('Home Shot Conversion Rate vs. Goals Remaining')\n",
    "plt.xlabel('Shot Conversion Rate')\n",
    "plt.ylabel('Potential Goals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the goals remaining vary despite most teams having a low attack efficiency means that this variabile could be due to other factors influencing the number of goals remaining that are not captured by attack efficiency and shot conversion alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='away_attack_efficiency', y='potential_goals', data=sports)\n",
    "plt.title('Away Attack Efficiency vs. Potential Goals')\n",
    "plt.xlabel('Home Attack Efficiency')\n",
    "plt.ylabel('Potential Goals')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sns.scatterplot(x='away_shot_conversion_rate', y='potential_goals', data=sports)\n",
    "plt.title('Away Shot Conversion Rate vs. Potential Goals')\n",
    "plt.xlabel('Shot Conversion Rate')\n",
    "plt.ylabel('Potential Goals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same interpretation can be concluded with the away attack efficiency, but it now differs with the away shot conversion rate where the points are much more scattered but is still mostly right-skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training is a crucial step in the machine learning pipeline. It involves learning the underlying patterns in the training data so that we can make predictions on unseen data. The goal is to find a model that generalizes well, meaning it accurately predicts the outcomes on new, unseen data based on the patterns it learned from the training data.\n",
    "\n",
    "In this project, we trained several types of regression models on our 'Sports' dataset:\n",
    "\n",
    "1. **Linear Regression**: This is a simple and commonly used type of regression that assumes a linear relationship between the input variables (x) and the single output variable (y). It can be used when the relationship between the input and output variables is approximately linear.\n",
    "\n",
    "2. **Regression Trees (Decision Trees)**: This is a type of model that breaks down our dataset into smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes, which provide a clear interpretation of why the model is making certain predictions.\n",
    "\n",
    "3. **Polynomial Regression**: This is a type of regression that models the relationship between the input variable (x) and the output variable (y) as an nth degree polynomial. Polynomial regression can model relationships between variables that aren't linear and can fit data with curves or slopes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "Getting the model ready for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sports = sports['home_attacks'].values.reshape(-1, 1)\n",
    "y_sports = sports['home_dangerous_attacks'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sports, y_sports, test_size=0.20, random_state=0)\n",
    "\n",
    "print('Training data shape:', X_train.shape)\n",
    "print('Ground truth values shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(X_train, y_train, 'ro', label='Original data')\n",
    "\n",
    "plt.ylabel('Home dangerous attacks')\n",
    "plt.xlabel('Home attacks')\n",
    "ax.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDRegressor(eta0=1e-9, max_iter=200, learning_rate='optimal', random_state=1, verbose=1, alpha=0.001)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the predicted linear regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X_train, y_train, 'ro', label='Original data')\n",
    "\n",
    "y_predicted = model.predict(X_train)\n",
    "line, = ax.plot(X_train, y_predicted, label='Regression line')\n",
    "\n",
    "ax.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show accuracy using RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = compute_RMSE(y_train, y_predicted)\n",
    "print('{:.2f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X_test, y_test, 'ro', label='Original data')\n",
    "\n",
    "y_predicted = model.predict(X_test)\n",
    "line, = ax.plot(X_test, y_predicted, label='Regression line')\n",
    "\n",
    "ax.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = compute_RMSE(y_test, y_predicted)\n",
    "print('{:.2f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis is a critical step in the machine learning pipeline, especially in regression models. It helps us understand how well our model is performing and where it’s falling short. By analyzing the residuals (the differences between the predicted and actual values), we can identify patterns that the model may have missed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a residual plot for error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_predicted  # Calculate residuals\n",
    "\n",
    "# Scatter plot of residuals vs. predicted values\n",
    "plt.scatter(y_predicted, residuals)  \n",
    "plt.xlabel(\"Predicted Home Dangerous Attacks\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chart above is a scatter plot of the residuals (the differences between the actual and the predicted values against the predicted values). Here we have a well performing model because the residuals are randomy scattered around at zero, with no clear pattern.\n",
    "\n",
    "This means that the model is correctly specified and that the error term in the underlying regression equation has a constant variance, suggesting that the model's predictions are fairly accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing all evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing all evaluation metrics provides a comprehensive understanding of a model's performance. Each metric offers unique insights into different aspects of the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate additional metrics (R-squared)\n",
    "r2 = r2_score(y_test, y_predicted)\n",
    "\n",
    "# Print all evaluation metrics\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_predicted))\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(y_test, y_predicted)))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_predicted))\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE is relatively low which means the model's predictions are faily close to the actual values. \n",
    "\n",
    "RMSE means that the predictions are only 0.1375 units away from actual.\n",
    "\n",
    "MAE indicates there are no strong influences to the RMSE\n",
    "\n",
    "R Squared means there is 73.96% of the variability in the output variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "Get the data ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sports = sports[['home_shot_conversion_rate',                   \n",
    "                  'away_shot_conversion_rate',\n",
    "                  'home_attack_efficiency',\n",
    "                  'away_attack_efficiency',\n",
    "                  'current_minute']].values\n",
    "y_sports = sports['potential_goals'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sports, y_sports, test_size=0.20, random_state=0)\n",
    "\n",
    "print('Training data shape:', X_train.shape)\n",
    "print('Ground truth values shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaggingRegressor(estimator=DecisionTreeRegressor(max_depth=7), random_state = 0, n_estimators=7)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Analysis and printing all evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a residual plot for error analysis also printed all evaluation metrics (MSE, MAE, R Squared, and RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the values\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculating residuals\n",
    "train_residuals = y_train - y_train_pred\n",
    "test_residuals = y_test - y_test_pred\n",
    "\n",
    "# Plotting residuals\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(y_train_pred, train_residuals, c='blue', marker='o', label='Training data')\n",
    "plt.scatter(y_test_pred, test_residuals, c='lightgreen', marker='s', label='Test data')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend(loc='upper left')\n",
    "plt.hlines(y=0, xmin=0, xmax=1, color='red')\n",
    "plt.show()\n",
    "\n",
    "# Printing evaluation metrics\n",
    "print(\"Training Metrics:\")\n",
    "print(\"Mean Squared Error: \", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Mean Absolute Error: \", mean_absolute_error(y_train, y_train_pred))\n",
    "print(\"R^2 Score: \", r2_score(y_train, y_train_pred))\n",
    "print(\"Root Mean Squared Error (RMSE):\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(\"Mean Squared Error: \", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Mean Absolute Error: \", mean_absolute_error(y_test, y_test_pred))\n",
    "print(\"R^2 Score: \", r2_score(y_test, y_test_pred))\n",
    "print(\"Root Mean Squared Error (RMSE):\", np.sqrt(mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the residuals it represents the difference between the actual values and the predicted values. Here we can see that the residuals are somewhat scattered around 0 but there is a slight pattern.\n",
    "\n",
    "The training residuals seem to be more concentrated around the zero which may mean that there is a slight overfitting of the training data.\n",
    "\n",
    "The MSE and RMSE are really low meaning there are only small errors in the model's prediction.\n",
    "\n",
    "There is strong correlation since the R Squared scores are high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the y value to the target variable and X to the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sports[['home_attack_efficiency',\n",
    "            'away_attack_efficiency', \n",
    "            'home_shot_conversion_rate', \n",
    "            'away_shot_conversion_rate',\n",
    "            'current_minute']]\n",
    "\n",
    "y = sports['potential_goals']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply polynomial features transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE is high which means the model's predictions are far from the actual. \n",
    "\n",
    "RMSE means that the predictions are 1.2868 units away from actual.\n",
    "\n",
    "The resulting evalutation tells us that the model is not performing well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'eta0': [1e-3, 1e-4, 1e-5],  # Learning rate\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # L1 regularization parameter\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(SGDRegressor(random_state=1), param_grid, cv=5, scoring='r2')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Use the best model for prediction\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on train and test sets using the best model\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "train_rmse = compute_RMSE(y_train, y_train_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "test_rmse = compute_RMSE(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print all evaluation metrics\n",
    "print(\"Train Metrics:\")\n",
    "print(\"  Mean Squared Error:\", train_mse)\n",
    "print(\"  Root Mean Squared Error:\", train_rmse)\n",
    "print(\"  Mean Absolute Error:\", train_mae)\n",
    "print(\"  R-squared:\", train_r2)\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(\"  Mean Squared Error:\", test_mse)\n",
    "print(\"  Root Mean Squared Error:\", test_rmse)\n",
    "print(\"  Mean Absolute Error:\", test_mae)\n",
    "print(\"  R-squared:\", test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These are the results:\n",
    "\n",
    "- Best Parameters: {'alpha': 0.0001, 'eta0': 0.001}\n",
    "- Best Score: 0.07001159914785912\n",
    "\n",
    "**Train Metrics:**\n",
    "- Mean Squared Error: 0.024995654090193435\n",
    "- Root Mean Squared Error: 0.15810013943761542\n",
    "- Mean Absolute Error: 0.12633720728724668\n",
    "- R-squared: 0.07746293106517332"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'estimator__max_depth': [3, 5, 7],  \n",
    "    'n_estimators': [50, 100, 150],  \n",
    "}\n",
    "\n",
    "# Create Bagging Regressor with DecisionTreeRegressor base estimator\n",
    "model = BaggingRegressor(estimator=DecisionTreeRegressor(random_state=0), random_state=0)\n",
    "\n",
    "# Perform grid search with R-squared scoring\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='r2', cv=5)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Train the model with best parameters on entire training set\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on training and test sets with best model\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "train_residuals = y_train - y_train_pred\n",
    "test_residuals = y_test - y_test_pred\n",
    "\n",
    "# Print evaluation metrics with best model\n",
    "print(\"\\nTrain Metrics:\")\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_train, y_train_pred))\n",
    "print(\"R-squared:\", r2_score(y_train, y_train_pred))\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_test_pred))\n",
    "print(\"R-squared:\", r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These are the results:\n",
    "\n",
    "- Best Parameters: {'estimator__max_depth': 7, 'n_estimators': 150}\n",
    "- Best Score: 0.873743163527551\n",
    "\n",
    "**Train Metrics:**\n",
    "- Mean Squared Error: 0.002218637296984191\n",
    "- Root Mean Squared Error: 0.04710241285734937\n",
    "- Mean Absolute Error: 0.025711594505075968\n",
    "- R-squared: 0.9181147594056243"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline without scaling\n",
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_distributions = {\n",
    "    'poly__degree': [1, 2, 3, 4, 5],  # Degrees of polynomial features\n",
    "    'regressor__fit_intercept': [True, False]  # Whether to calculate the intercept\n",
    "}\n",
    "\n",
    "# Perform randomized search (using 'r2' for hyperparameter tuning)\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions, n_iter=10, cv=5, scoring='r2', n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best R-squared score:\", random_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on train and test sets\n",
    "best_model = random_search.best_estimator_\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics for train and test sets\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print all evaluation metrics\n",
    "print(\"\\nTrain Metrics:\")\n",
    "print(\"  Mean Squared Error:\", train_mse)\n",
    "print(\"  Root Mean Squared Error:\", train_rmse)\n",
    "print(\"  Mean Absolute Error:\", train_mae)\n",
    "print(\"  R-squared:\", train_r2)\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(\"  Mean Squared Error:\", test_mse)\n",
    "print(\"  Root Mean Squared Error:\", test_rmse)\n",
    "print(\"  Mean Absolute Error:\", test_mae)\n",
    "print(\"  R-squared:\", test_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These are the results:\n",
    "\n",
    "- Best parameters: {'regressor__fit_intercept': False, 'poly__degree': 2}\n",
    "- Best R-squared score: 0.8322812324337265\n",
    "\n",
    "**Train Metrics:**\n",
    "- Mean Squared Error: 0.0037156122363760525\n",
    "- Root Mean Squared Error: 0.060955822005580834\n",
    "- Mean Absolute Error: 0.038374204271194604\n",
    "- R-squared: 0.8628645599960688"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters: {'regressor__fit_intercept': False, 'poly__degree': 2}\n",
    "\n",
    "Best R-squared score: 0.8322812324337348\n",
    "\n",
    "Test MSE: 1.6558916980757519\n",
    "\n",
    "Test RMSE: 1.2868145546564789\n",
    "\n",
    "Test R-squared: -61.81931414615804\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
